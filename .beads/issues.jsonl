{"id":"toolhub-37j","title":"Epic: Phase 3 - Spec Mode","description":"Add OpenAPI/Swagger spec parsing for structured API queries alongside semantic search.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-11T18:18:40.338931-06:00","updated_at":"2025-12-11T20:34:25.061403-06:00","closed_at":"2025-12-11T20:34:25.061403-06:00"}
{"id":"toolhub-37j.1","title":"OpenAPI spec support","description":"Detect OpenAPI/Swagger files (openapi.*, swagger.*), parse them into structured operations. May require adding SQLite for operations table. Implement hybrid query routing: spec results + docs results with fallback.","status":"closed","priority":2,"issue_type":"task","assignee":"Keen-Hawk-31","created_at":"2025-12-11T18:18:45.833976-06:00","updated_at":"2025-12-11T20:34:08.270435-06:00","closed_at":"2025-12-11T20:34:08.270435-06:00","dependencies":[{"issue_id":"toolhub-37j.1","depends_on_id":"toolhub-37j","type":"parent-child","created_at":"2025-12-11T18:18:45.834455-06:00","created_by":"daemon"}]}
{"id":"toolhub-4k5","title":"Epic: Phase 2 - llms.txt + Claude Code Plugin","description":"Add llms.txt source type support and create Claude Code plugin with skill, sub-agent, and slash command for seamless agent integration.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-11T18:18:24.393176-06:00","updated_at":"2025-12-11T20:29:41.76044-06:00","closed_at":"2025-12-11T20:29:41.76044-06:00","dependencies":[{"issue_id":"toolhub-4k5","depends_on_id":"toolhub-chc","type":"blocks","created_at":"2025-12-11T18:19:47.421757-06:00","created_by":"daemon"}]}
{"id":"toolhub-4k5.1","title":"llms.txt crawler","description":"Implement crawler/llmstxt.py to detect and parse llms.txt files from URLs. Follow the llms.txt standard for AI-friendly documentation. Integrate with existing indexing pipeline.","status":"closed","priority":2,"issue_type":"task","assignee":"winnie","created_at":"2025-12-11T18:18:31.123053-06:00","updated_at":"2025-12-11T20:28:14.633356-06:00","closed_at":"2025-12-11T20:28:14.633356-06:00","dependencies":[{"issue_id":"toolhub-4k5.1","depends_on_id":"toolhub-4k5","type":"parent-child","created_at":"2025-12-11T18:18:31.12358-06:00","created_by":"daemon"}]}
{"id":"toolhub-4k5.2","title":"Claude Code plugin","description":"Create toolhub-plugin/ with plugin.json, skills/using-toolhub.md (teaches when/how to use toolhub), agents/toolhub-librarian.md (sub-agent for lookups returning 200-300 token summaries), and commands/toolhub-search.md (slash command wrapper).","status":"closed","priority":2,"issue_type":"task","assignee":"Keen-Hawk-31","created_at":"2025-12-11T18:18:31.358214-06:00","updated_at":"2025-12-11T20:26:25.481741-06:00","closed_at":"2025-12-11T20:26:25.481741-06:00","dependencies":[{"issue_id":"toolhub-4k5.2","depends_on_id":"toolhub-4k5","type":"parent-child","created_at":"2025-12-11T18:18:31.358702-06:00","created_by":"daemon"}]}
{"id":"toolhub-80t","title":"Epic: Phase 1 - KnowledgeStore Core","description":"Core storage APIs for the unified knowledge store: Postgres + S3 store implementation with add_source, store_artifact, add_chunk (with pgvector embeddings), and hybrid search (vector + FTS weighted merge).","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-14T11:32:53.479233-06:00","updated_at":"2025-12-14T11:32:53.479233-06:00"}
{"id":"toolhub-80t.1","title":"Implement Postgres + S3 store APIs","description":"Implement the KnowledgeStore class with full ingest and query pipeline:\n- add_source(): Insert source record in Postgres with collection/tags/status\n- store_artifact(): Upload raw/extracted/manifest to S3 with {env}/{collection}/{source_id}/{kind} key convention\n- add_chunk(): Store chunk text + heading info + embedding (pgvector) + generated tsvector\n- search(): Hybrid retrieval combining pgvector cosine similarity + FTS with weighted merge (0.7 semantic, 0.3 keyword)\n\nInclude integration tests covering: source → S3 artifacts → Postgres chunks → embeddings → hybrid search returning results with citations.\n\nAcceptance criteria:\n- Integration tests pass for full ingest pipeline\n- Hybrid search returns ranked results with source citations\n- S3 artifacts retrievable for rebuild scenarios","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-14T11:39:33.621714-06:00","updated_at":"2025-12-14T11:39:33.621714-06:00","dependencies":[{"issue_id":"toolhub-80t.1","depends_on_id":"toolhub-80t","type":"parent-child","created_at":"2025-12-14T11:39:33.622453-06:00","created_by":"daemon"},{"issue_id":"toolhub-80t.1","depends_on_id":"toolhub-lc0.1","type":"blocks","created_at":"2025-12-14T11:40:02.891919-06:00","created_by":"daemon"}]}
{"id":"toolhub-ad2","title":"Epic: Phase 4 - Website Crawling","description":"Add support for crawling documentation websites with proper rate limiting and robots.txt respect.","status":"closed","priority":3,"issue_type":"epic","created_at":"2025-12-11T18:18:55.669013-06:00","updated_at":"2025-12-11T20:36:45.976851-06:00","closed_at":"2025-12-11T20:36:45.976851-06:00"}
{"id":"toolhub-ad2.1","title":"Website crawler","description":"Implement crawler/website.py for HTML → markdown conversion. Respect robots.txt, implement depth/page limits, and add rate limiting. Support common documentation site patterns.","status":"closed","priority":3,"issue_type":"task","assignee":"winnie","created_at":"2025-12-11T18:19:00.291926-06:00","updated_at":"2025-12-11T20:36:31.062616-06:00","closed_at":"2025-12-11T20:36:31.062616-06:00","dependencies":[{"issue_id":"toolhub-ad2.1","depends_on_id":"toolhub-ad2","type":"parent-child","created_at":"2025-12-11T18:19:00.292444-06:00","created_by":"daemon"}]}
{"id":"toolhub-chc","title":"Epic: Phase 1 - Core CLI + Lazy Daemon","description":"Foundation for toolhub: project setup, core storage layer, GitHub crawling, indexing pipeline, CLI commands, and lazy daemon. This phase delivers a working end-to-end system for indexing GitHub repos and searching them.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-11T18:17:54.288489-06:00","updated_at":"2025-12-11T20:22:53.429728-06:00","closed_at":"2025-12-11T20:22:53.429728-06:00"}
{"id":"toolhub-chc.1","title":"Project scaffolding and storage layer","description":"Set up the Python project with uv init, pyproject.toml with all dependencies (typer, fastapi, uvicorn, httpx, lancedb, sentence-transformers, gitpython, rich). Implement config.py (load/save config.toml) and registry.py (load/save sources.json). Create the ~/.toolhub/ directory structure.","status":"closed","priority":1,"issue_type":"task","assignee":"bodhi","created_at":"2025-12-11T18:18:08.379453-06:00","updated_at":"2025-12-11T19:55:22.660468-06:00","closed_at":"2025-12-11T19:55:22.660468-06:00","dependencies":[{"issue_id":"toolhub-chc.1","depends_on_id":"toolhub-chc","type":"parent-child","created_at":"2025-12-11T18:18:08.379992-06:00","created_by":"daemon"}]}
{"id":"toolhub-chc.2","title":"GitHub repo crawler","description":"Implement crawler/github.py to clone/fetch GitHub repos (shallow clone), extract documentation files (README*, docs/**, examples/**), and save to ~/.toolhub/cache/{tool_id}/. Include crawler/base.py with abstract crawler interface for future source types.","status":"closed","priority":1,"issue_type":"task","assignee":"winnie","created_at":"2025-12-11T18:18:08.608074-06:00","updated_at":"2025-12-11T19:58:47.901265-06:00","closed_at":"2025-12-11T19:58:47.901265-06:00","dependencies":[{"issue_id":"toolhub-chc.2","depends_on_id":"toolhub-chc","type":"parent-child","created_at":"2025-12-11T18:18:08.608518-06:00","created_by":"daemon"},{"issue_id":"toolhub-chc.2","depends_on_id":"toolhub-chc.1","type":"blocks","created_at":"2025-12-11T18:19:38.618148-06:00","created_by":"daemon"}]}
{"id":"toolhub-chc.3","title":"Markdown chunker and embedder","description":"Implement indexer/chunker.py to split markdown by headers and code blocks (~500 tokens per chunk) with metadata (source file, heading hierarchy). Implement indexer/embedder.py using sentence-transformers (all-MiniLM-L6-v2) to generate embeddings.","status":"closed","priority":1,"issue_type":"task","assignee":"bodhi","created_at":"2025-12-11T18:18:08.833066-06:00","updated_at":"2025-12-11T19:59:30.148754-06:00","closed_at":"2025-12-11T19:59:30.148754-06:00","dependencies":[{"issue_id":"toolhub-chc.3","depends_on_id":"toolhub-chc","type":"parent-child","created_at":"2025-12-11T18:18:08.833512-06:00","created_by":"daemon"},{"issue_id":"toolhub-chc.3","depends_on_id":"toolhub-chc.1","type":"blocks","created_at":"2025-12-11T18:19:38.893695-06:00","created_by":"daemon"}]}
{"id":"toolhub-chc.4","title":"LanceDB vector store","description":"Implement store/lance.py as a wrapper around LanceDB. Handle per-tool .lance directories, adding/querying embeddings, and deletion. Implement search.py for query logic with JSON and markdown output formatting.","status":"closed","priority":1,"issue_type":"task","assignee":"winnie","created_at":"2025-12-11T18:18:09.080774-06:00","updated_at":"2025-12-11T20:03:27.629486-06:00","closed_at":"2025-12-11T20:03:27.629486-06:00","dependencies":[{"issue_id":"toolhub-chc.4","depends_on_id":"toolhub-chc","type":"parent-child","created_at":"2025-12-11T18:18:09.081217-06:00","created_by":"daemon"},{"issue_id":"toolhub-chc.4","depends_on_id":"toolhub-chc.3","type":"blocks","created_at":"2025-12-11T18:19:39.178042-06:00","created_by":"daemon"}]}
{"id":"toolhub-chc.5","title":"CLI commands","description":"Implement cli.py with Typer: add (with --replace), search (with --limit, --format), list, info, remove (with --source), status, stop. Wire commands to daemon via client.py HTTP calls.","status":"closed","priority":1,"issue_type":"task","assignee":"winnie","created_at":"2025-12-11T18:18:09.322815-06:00","updated_at":"2025-12-11T20:16:27.07703-06:00","closed_at":"2025-12-11T20:16:27.07703-06:00","dependencies":[{"issue_id":"toolhub-chc.5","depends_on_id":"toolhub-chc","type":"parent-child","created_at":"2025-12-11T18:18:09.323253-06:00","created_by":"daemon"},{"issue_id":"toolhub-chc.5","depends_on_id":"toolhub-chc.4","type":"blocks","created_at":"2025-12-11T18:19:39.448169-06:00","created_by":"daemon"},{"issue_id":"toolhub-chc.5","depends_on_id":"toolhub-chc.2","type":"blocks","created_at":"2025-12-11T18:19:39.716357-06:00","created_by":"daemon"}]}
{"id":"toolhub-chc.6","title":"Lazy daemon","description":"Implement daemon.py with FastAPI server on localhost:9742. Endpoints: POST /tools/add, POST /tools/query, GET /tools, GET /tools/{id}, POST /tools/{id}/update, DELETE /tools/{id}, GET /health. Implement lazy start logic in client.py — auto-spawn daemon if not running.","status":"closed","priority":1,"issue_type":"task","assignee":"winnie","created_at":"2025-12-11T18:18:09.634305-06:00","updated_at":"2025-12-11T20:22:08.590053-06:00","closed_at":"2025-12-11T20:22:08.590053-06:00","dependencies":[{"issue_id":"toolhub-chc.6","depends_on_id":"toolhub-chc","type":"parent-child","created_at":"2025-12-11T18:18:09.634787-06:00","created_by":"daemon"},{"issue_id":"toolhub-chc.6","depends_on_id":"toolhub-chc.5","type":"blocks","created_at":"2025-12-11T18:19:39.956719-06:00","created_by":"daemon"}]}
{"id":"toolhub-i1l","title":"Epic: Phase 5 - Polish","description":"Quality-of-life improvements: recommendations, background updates, and rich terminal output.","status":"closed","priority":3,"issue_type":"epic","created_at":"2025-12-11T18:19:09.440067-06:00","updated_at":"2025-12-11T20:59:22.570483-06:00","closed_at":"2025-12-11T20:59:22.570483-06:00"}
{"id":"toolhub-i1l.1","title":"Recommend command","description":"Implement 'toolhub recommend \u003cname\u003e' to suggest source URLs for common libraries based on a curated registry or web search.","status":"closed","priority":3,"issue_type":"task","assignee":"Steady-Raven-23","created_at":"2025-12-11T18:19:15.360566-06:00","updated_at":"2025-12-11T20:58:57.343022-06:00","closed_at":"2025-12-11T20:58:57.343022-06:00","dependencies":[{"issue_id":"toolhub-i1l.1","depends_on_id":"toolhub-i1l","type":"parent-child","created_at":"2025-12-11T18:19:15.361069-06:00","created_by":"daemon"}]}
{"id":"toolhub-i1l.2","title":"Background updates and rich output","description":"Add background update scheduler for automatic re-crawling. Implement rich terminal output with progress bars and tables for better UX.","status":"closed","priority":4,"issue_type":"task","assignee":"Steady-Raven-23","created_at":"2025-12-11T18:19:15.606402-06:00","updated_at":"2025-12-11T20:40:35.063255-06:00","closed_at":"2025-12-11T20:40:35.063255-06:00","dependencies":[{"issue_id":"toolhub-i1l.2","depends_on_id":"toolhub-i1l","type":"parent-child","created_at":"2025-12-11T18:19:15.606883-06:00","created_by":"daemon"}]}
{"id":"toolhub-lc0","title":"Epic: Phase 0 - Scaffold + Contracts","description":"Foundation for unified knowledge store: Postgres + S3 configuration, schema.sql with migrations, Procfile/honcho dev workflow, and test harness skeleton with Docker fixtures for pgvector + MinIO.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-14T11:32:34.307722-06:00","updated_at":"2025-12-14T11:32:34.307722-06:00"}
{"id":"toolhub-lc0.1","title":"Scaffold project infrastructure","description":"Add Postgres + S3 config keys to config system. Create schema.sql with all tables (sources, source_artifacts, chunks with embedding column, entity_types, entities, evidence) plus indexes (IVFFLAT on embeddings, GIN on search_vector/JSONB, btree on collections). Add Procfile for honcho workflow (MinIO + API). Create test harness skeleton with pytest fixtures for Docker-based Postgres (pgvector) + MinIO isolation per worker.\n\nAcceptance criteria:\n- honcho start runs MinIO + daemon\n- task db:migrate applies schema successfully\n- Test fixtures can spin up isolated Postgres/MinIO for parallel tests","status":"in_progress","priority":1,"issue_type":"task","assignee":"Keen-Heron-37","created_at":"2025-12-14T11:39:21.530684-06:00","updated_at":"2025-12-14T11:43:36.767206-06:00","dependencies":[{"issue_id":"toolhub-lc0.1","depends_on_id":"toolhub-lc0","type":"parent-child","created_at":"2025-12-14T11:39:21.531252-06:00","created_by":"daemon"}]}
{"id":"toolhub-met","title":"Epic: Phase 2 - Entities + Evidence","description":"Entity modeling layer: JSON Schema registry with versioning, entity CRUD with profile validation, and evidence model linking claims to source chunks with field_path precision.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-14T11:32:56.320791-06:00","updated_at":"2025-12-14T11:32:56.320791-06:00"}
{"id":"toolhub-met.1","title":"Implement entity schema registry and CRUD","description":"Implement entity_types schema registry with JSON Schema validation:\n- register_entity_type(): Upsert schema with automatic version increment on change\n- Entity CRUD (create/read/update/delete) with app-level profile validation against registered schemas\n- Schema caching in-process for daemon + CLI performance\n\nExample entity types: competitor (name, description, features[], funding{}, team_size), wisdom (topic, summary, key_points[], links[]).\n\nInclude tests for:\n- Invalid profile rejection (schema violation)\n- Valid profile acceptance\n- Schema versioning on updates\n\nAcceptance criteria:\n- register_entity_type() upserts and versions schemas correctly\n- Entity create/update validates profile against schema\n- Invalid profiles raise clear validation errors with field paths","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-14T11:39:37.262561-06:00","updated_at":"2025-12-14T11:39:37.262561-06:00","dependencies":[{"issue_id":"toolhub-met.1","depends_on_id":"toolhub-met","type":"parent-child","created_at":"2025-12-14T11:39:37.263068-06:00","created_by":"daemon"},{"issue_id":"toolhub-met.1","depends_on_id":"toolhub-80t.1","type":"blocks","created_at":"2025-12-14T11:40:03.285427-06:00","created_by":"daemon"}]}
{"id":"toolhub-met.2","title":"Implement evidence model and retrieval","description":"Implement evidence system for linking entity claims to source chunks:\n- Evidence CRUD with field_path linking (e.g., 'features', 'funding.total', 'pricing.notes[0]')\n- Reference chunk_id (preferred) or source_id fallback\n- Optional quote extraction and confidence scoring\n- Evidence retrieval grouped by entity/field for citation assembly\n\nInclude tests for:\n- Evidence linkage (field_path → chunk_id with quote)\n- Retrieval grouping by entity\n- Citation rendering (chunk excerpt + heading_path + canonical_url)\n\nAcceptance criteria:\n- Evidence rows correctly link field_path to chunks\n- Retrieval returns evidence grouped by entity with citations\n- Citations render with proper attribution","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-14T11:39:40.16728-06:00","updated_at":"2025-12-14T11:39:40.16728-06:00","dependencies":[{"issue_id":"toolhub-met.2","depends_on_id":"toolhub-met","type":"parent-child","created_at":"2025-12-14T11:39:40.167791-06:00","created_by":"daemon"},{"issue_id":"toolhub-met.2","depends_on_id":"toolhub-met.1","type":"blocks","created_at":"2025-12-14T11:40:03.655294-06:00","created_by":"daemon"}]}
{"id":"toolhub-qll","title":"Epic: Phase 3 - Reports","description":"Deterministic report generation framework: base Report class with ReportResult (markdown + JSON output), plus three v1 reports: competitor feature matrix, fundraising timeline, and wisdom digest.","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-14T11:33:00.216891-06:00","updated_at":"2025-12-14T11:33:00.216891-06:00"}
{"id":"toolhub-qll.1","title":"Implement reports engine with v1 reports","description":"Implement deterministic report generation framework:\n- Base Report class with generate(**kwargs) returning ReportResult\n- ReportResult with to_markdown() and to_json() output methods\n- Three v1 reports:\n  1. Competitor feature matrix (tag-filtered or explicit entity list)\n  2. Competitor fundraising timeline (from profile + evidence)\n  3. Wisdom digest by topic/tags\n\nTests must validate:\n- Correct union of features across competitors\n- Stable markdown format (deterministic output)\n- Citations included when evidence exists\n- JSON output structure matches spec\n\nAcceptance criteria:\n- All three reports generate consistent markdown/JSON\n- Reports include citations when evidence exists\n- Tests verify deterministic output across runs","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T11:39:43.152658-06:00","updated_at":"2025-12-14T11:39:43.152658-06:00","dependencies":[{"issue_id":"toolhub-qll.1","depends_on_id":"toolhub-qll","type":"parent-child","created_at":"2025-12-14T11:39:43.153183-06:00","created_by":"daemon"},{"issue_id":"toolhub-qll.1","depends_on_id":"toolhub-met.2","type":"blocks","created_at":"2025-12-14T11:40:04.02494-06:00","created_by":"daemon"}]}
{"id":"toolhub-qn0","title":"Epic: Phase 4 - CLI + API Integration","description":"Wire new storage into daemon and CLI: /query with structured filters, /entities/*, /evidence/*, /reports/* endpoints, plus CLI wrappers for daily usage workflows.","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-14T11:33:04.097103-06:00","updated_at":"2025-12-14T11:33:04.097103-06:00"}
{"id":"toolhub-qn0.1","title":"Add API endpoints for query, entities, evidence, reports","description":"Wire new storage into daemon endpoints and CLI:\n\nAPI endpoints:\n- /query: Support structured filters (collection, tags, type_key, entity_id, time ranges, limit, min_similarity)\n- /entities/*: CRUD for entity management\n- /evidence/*: CRUD for evidence management  \n- /reports/*: Report generation with filter parameters\n\nCLI wrappers:\n- Query with filters (toolhub query --collection X --tags Y)\n- Entity management (toolhub entity create/list/show/update/delete)\n- Evidence management (toolhub evidence add/list/show)\n- Report generation (toolhub report competitor-matrix --tags Z)\n\nInclude integration tests for API → Postgres → response flow.\n\nAcceptance criteria:\n- CLI can query with all supported filters\n- Entity/evidence CRUD works end-to-end\n- Reports generate via both API and CLI","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T11:39:45.870888-06:00","updated_at":"2025-12-14T11:39:45.870888-06:00","dependencies":[{"issue_id":"toolhub-qn0.1","depends_on_id":"toolhub-qn0","type":"parent-child","created_at":"2025-12-14T11:39:45.871384-06:00","created_by":"daemon"},{"issue_id":"toolhub-qn0.1","depends_on_id":"toolhub-qll.1","type":"blocks","created_at":"2025-12-14T11:40:04.405398-06:00","created_by":"daemon"}]}
{"id":"toolhub-uu9","title":"Epic: Phase 5 - Cutover","description":"Complete migration: remove LanceDB + SQLite code paths, update all operations to use only Postgres + S3, keep old files on disk but stop reading/writing them.","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-14T11:33:06.471335-06:00","updated_at":"2025-12-14T11:33:06.471335-06:00"}
{"id":"toolhub-uu9.1","title":"Replace LanceDB + SQLite storage path","description":"Complete migration from old storage to new unified Postgres + S3:\n\nCode changes:\n- Remove all LanceDB imports and code paths (store/lance.py)\n- Remove operations SQLite DB usage (store/operations.py for old path)\n- Update all CLI commands to use only new KnowledgeStore\n- Update daemon endpoints to use only new storage backend\n\nCleanup:\n- Keep old files on disk (~/.toolhub/stores/, operations.db) but stop reading/writing\n- Update documentation to reflect new architecture\n- Remove deprecated configuration options\n\nVerification:\n- All existing toolhub workflows function correctly with new backend\n- No LanceDB/SQLite imports remain in active code paths\n- Integration tests pass with new storage only\n\nAcceptance criteria:\n- grep for lancedb/sqlite shows no active imports\n- All CLI commands work with Postgres + S3\n- Documentation updated","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T11:39:49.064277-06:00","updated_at":"2025-12-14T11:39:49.064277-06:00","dependencies":[{"issue_id":"toolhub-uu9.1","depends_on_id":"toolhub-uu9","type":"parent-child","created_at":"2025-12-14T11:39:49.064789-06:00","created_by":"daemon"},{"issue_id":"toolhub-uu9.1","depends_on_id":"toolhub-qn0.1","type":"blocks","created_at":"2025-12-14T11:40:04.788265-06:00","created_by":"daemon"}]}
